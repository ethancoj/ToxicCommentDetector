{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdt1W69QPSAo"
   },
   "source": [
    "### Toxic Comment Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6dZ0xPDGNEui"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from googleapiclient.discovery import build\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, hamming_loss, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gradio as gr\n",
    "import re\n",
    "import ftfy\n",
    "import io\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import json\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wc8YozvPKVa"
   },
   "source": [
    "**IMPORT THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "v4xcHUNocBdc",
    "outputId": "9204f402-a1e0-450e-f7fe-b84a8dd722e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009801bd85e5806</td>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009eaea3325de8c</td>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000b08c464718505</td>\n",
       "      <td>\"\\n\\n Regarding your recent edits \\n\\nOnce aga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000bfd0867774845</td>\n",
       "      <td>\"\\nGood to know. About me, yeah, I'm studying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000c0dfd995809fa</td>\n",
       "      <td>\"\\n\\n Snowflakes are NOT always symmetrical! \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000c6a3f0cd3ba8e</td>\n",
       "      <td>\"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000cfee90f50d471</td>\n",
       "      <td>\"\\n\\nRe-considering 1st paragraph edit?\\nI don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "0   0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2   000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3   0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4   0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "5   00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n",
       "8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n",
       "9   00040093b2687caa  alignment on this subject and which are contra...   \n",
       "10  0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...   \n",
       "11  00054a5e18b50dd4  bbq \\n\\nbe a man and lets discuss it-maybe ove...   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "13  0006f16e4e9f292e  Before you start throwing accusations and warn...   \n",
       "14  00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n",
       "15  00078f8ce7eb276d  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "17  000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n",
       "18  0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n",
       "19  0009eaea3325de8c  Don't mean to bother you \\n\\nI see that you're...   \n",
       "20  000b08c464718505  \"\\n\\n Regarding your recent edits \\n\\nOnce aga...   \n",
       "21  000bfd0867774845  \"\\nGood to know. About me, yeah, I'm studying ...   \n",
       "22  000c0dfd995809fa  \"\\n\\n Snowflakes are NOT always symmetrical! \\...   \n",
       "23  000c6a3f0cd3ba8e  \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...   \n",
       "24  000cfee90f50d471  \"\\n\\nRe-considering 1st paragraph edit?\\nI don...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0       0             0        0       0       0              0  \n",
       "1       0             0        0       0       0              0  \n",
       "2       0             0        0       0       0              0  \n",
       "3       0             0        0       0       0              0  \n",
       "4       0             0        0       0       0              0  \n",
       "5       0             0        0       0       0              0  \n",
       "6       1             1        1       0       1              0  \n",
       "7       0             0        0       0       0              0  \n",
       "8       0             0        0       0       0              0  \n",
       "9       0             0        0       0       0              0  \n",
       "10      0             0        0       0       0              0  \n",
       "11      0             0        0       0       0              0  \n",
       "12      1             0        0       0       0              0  \n",
       "13      0             0        0       0       0              0  \n",
       "14      0             0        0       0       0              0  \n",
       "15      0             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "17      0             0        0       0       0              0  \n",
       "18      0             0        0       0       0              0  \n",
       "19      0             0        0       0       0              0  \n",
       "20      0             0        0       0       0              0  \n",
       "21      0             0        0       0       0              0  \n",
       "22      0             0        0       0       0              0  \n",
       "23      0             0        0       0       0              0  \n",
       "24      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ethan\n",
    "# df = pd.read_csv('/content/drive/MyDrive/toxic comment detector/train.csv')\n",
    "#coedd\n",
    "# df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tcd/train.csv')\n",
    "# df.head(25)\n",
    "\n",
    "#isyraf\n",
    "df = pd.read_csv('C:/Users/Haisha/Desktop/2025/NLP/train.csv')\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rkIX3Ka_Ncmp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu2tQN1ROstb"
   },
   "source": [
    "**CLEANING THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w4rC-SwOOxYY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9fgSflfdQ5pJ"
   },
   "outputs": [],
   "source": [
    "#Replace newlines, tabs, carriage returns with space\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: re.sub(r'[\\n\\r\\t]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iVPH-yNlgccU"
   },
   "outputs": [],
   "source": [
    "#Strip leading and trailing whitespace\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "60sxieLsguwt"
   },
   "outputs": [],
   "source": [
    "#Remove excessive spaces\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PRImXbSmg6O-"
   },
   "outputs": [],
   "source": [
    "#Fix Encoding Artifacts (like Ã¢â‚¬â„¢, ÃƒÂ©)\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: ftfy.fix_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PXZqwQ9IhNnq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: toxic\n",
      "[0 1]\n",
      "\n",
      "Column: severe_toxic\n",
      "[0 1]\n",
      "\n",
      "Column: obscene\n",
      "[0 1]\n",
      "\n",
      "Column: threat\n",
      "[0 1]\n",
      "\n",
      "Column: insult\n",
      "[0 1]\n",
      "\n",
      "Column: identity_hate\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "excluded_cols = ['id', 'comment_text']\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in excluded_cols:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(df[col].unique()) #print all value for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "74vnan4okYKY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" More I can't make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\" Congratulations from me as well, use the too...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>\" Fair use rationale for Image:Wonju.jpg Thank...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq be a man and lets discuss it-maybe over th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it.. @ | talk . What is it... a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>\" Juelz Santanas Age In 2002, Juelz Santana wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! Don't look, come or think of comming back...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009801bd85e5806</td>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009eaea3325de8c</td>\n",
       "      <td>Don't mean to bother you I see that you're wri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000b08c464718505</td>\n",
       "      <td>\" Regarding your recent edits Once again, plea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000bfd0867774845</td>\n",
       "      <td>\" Good to know. About me, yeah, I'm studying n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000c0dfd995809fa</td>\n",
       "      <td>\" Snowflakes are NOT always symmetrical! Under...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000c6a3f0cd3ba8e</td>\n",
       "      <td>\" The Signpost: 24 September 2012 Read this Si...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000cfee90f50d471</td>\n",
       "      <td>\" Re-considering 1st paragraph edit? I don't u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000eefc67a2c930f</td>\n",
       "      <td>Radial symmetry Several now extinct lineages i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000f35deef84dc4a</td>\n",
       "      <td>There's no need to apologize. A Wikipedia arti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000ffab30195c5e1</td>\n",
       "      <td>Yes, because the mother of the child in the ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0010307a3a50a353</td>\n",
       "      <td>\" Ok. But it will take a bit of work but I can...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0010833a96e1f886</td>\n",
       "      <td>\"== A barnstar for you! == The Real Life Barns...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "0   0000997932d777bf  Explanation Why the edits made under my userna...   \n",
       "1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2   000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3   0001b41b1c6bb37e  \" More I can't make any real suggestions on im...   \n",
       "4   0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "5   00025465d4725e87  \" Congratulations from me as well, use the too...   \n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n",
       "8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n",
       "9   00040093b2687caa  alignment on this subject and which are contra...   \n",
       "10  0005300084f90edc  \" Fair use rationale for Image:Wonju.jpg Thank...   \n",
       "11  00054a5e18b50dd4  bbq be a man and lets discuss it-maybe over th...   \n",
       "12  0005c987bdfc9d4b  Hey... what is it.. @ | talk . What is it... a...   \n",
       "13  0006f16e4e9f292e  Before you start throwing accusations and warn...   \n",
       "14  00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n",
       "15  00078f8ce7eb276d  \" Juelz Santanas Age In 2002, Juelz Santana wa...   \n",
       "16  0007e25b2121310b  Bye! Don't look, come or think of comming back...   \n",
       "17  000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n",
       "18  0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n",
       "19  0009eaea3325de8c  Don't mean to bother you I see that you're wri...   \n",
       "20  000b08c464718505  \" Regarding your recent edits Once again, plea...   \n",
       "21  000bfd0867774845  \" Good to know. About me, yeah, I'm studying n...   \n",
       "22  000c0dfd995809fa  \" Snowflakes are NOT always symmetrical! Under...   \n",
       "23  000c6a3f0cd3ba8e  \" The Signpost: 24 September 2012 Read this Si...   \n",
       "24  000cfee90f50d471  \" Re-considering 1st paragraph edit? I don't u...   \n",
       "25  000eefc67a2c930f  Radial symmetry Several now extinct lineages i...   \n",
       "26  000f35deef84dc4a  There's no need to apologize. A Wikipedia arti...   \n",
       "27  000ffab30195c5e1  Yes, because the mother of the child in the ca...   \n",
       "28  0010307a3a50a353  \" Ok. But it will take a bit of work but I can...   \n",
       "29  0010833a96e1f886  \"== A barnstar for you! == The Real Life Barns...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0       0             0        0       0       0              0  \n",
       "1       0             0        0       0       0              0  \n",
       "2       0             0        0       0       0              0  \n",
       "3       0             0        0       0       0              0  \n",
       "4       0             0        0       0       0              0  \n",
       "5       0             0        0       0       0              0  \n",
       "6       1             1        1       0       1              0  \n",
       "7       0             0        0       0       0              0  \n",
       "8       0             0        0       0       0              0  \n",
       "9       0             0        0       0       0              0  \n",
       "10      0             0        0       0       0              0  \n",
       "11      0             0        0       0       0              0  \n",
       "12      1             0        0       0       0              0  \n",
       "13      0             0        0       0       0              0  \n",
       "14      0             0        0       0       0              0  \n",
       "15      0             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "17      0             0        0       0       0              0  \n",
       "18      0             0        0       0       0              0  \n",
       "19      0             0        0       0       0              0  \n",
       "20      0             0        0       0       0              0  \n",
       "21      0             0        0       0       0              0  \n",
       "22      0             0        0       0       0              0  \n",
       "23      0             0        0       0       0              0  \n",
       "24      0             0        0       0       0              0  \n",
       "25      0             0        0       0       0              0  \n",
       "26      0             0        0       0       0              0  \n",
       "27      0             0        0       0       0              0  \n",
       "28      0             0        0       0       0              0  \n",
       "29      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aip8ez0kike"
   },
   "source": [
    "**TRAIN THE MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4ab2o8-bWyZa"
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128, model_name=\"\"):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.model_name = model_name.lower()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "\n",
    "        # Handle different tokenizer requirements\n",
    "        tokenizer_kwargs = {\n",
    "            'text': text,\n",
    "            'add_special_tokens': True,\n",
    "            'max_length': self.max_len,\n",
    "            'padding': 'max_length',\n",
    "            'truncation': True,\n",
    "            'return_attention_mask': True,\n",
    "            'return_tensors': 'pt'\n",
    "        }\n",
    "\n",
    "        # Only add token_type_ids for models that support it (not DistilBERT)\n",
    "        if 'distilbert' not in self.model_name:\n",
    "            tokenizer_kwargs['return_token_type_ids'] = True\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(**tokenizer_kwargs)\n",
    "\n",
    "        result = {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "        # Add token_type_ids only if it exists in inputs\n",
    "        if 'token_type_ids' in inputs:\n",
    "            result['token_type_ids'] = inputs['token_type_ids'].flatten()\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BgXTZslzXJd3"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()\n",
    "\n",
    "    # Convert to binary predictions\n",
    "    binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(labels.shape[1]):\n",
    "        if len(np.unique(labels[:, i])) > 1:  # Check if both classes exist\n",
    "            auc = roc_auc_score(labels[:, i], predictions[:, i])\n",
    "            auc_scores.append(auc)\n",
    "            f1 = f1_score(labels[:, i], binary_predictions[:, i])\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        'auc': np.mean(auc_scores),\n",
    "        'f1': np.mean(f1_scores)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XZP_axw2XOYK"
   },
   "outputs": [],
   "source": [
    "class ToxicCommentDetector:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.tokenizers = {}\n",
    "        # self.thresholds = {}\n",
    "        self.label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "        # Model configurations optimized for Colab\n",
    "        self.model_configs = {\n",
    "            'DistilBERT': {\n",
    "                'name': 'distilbert-base-uncased',\n",
    "                'max_len': 128,\n",
    "                'batch_size': 16,\n",
    "                'epochs': 3,\n",
    "                'lr': 2e-5\n",
    "            },\n",
    "            'RoBERTa': {\n",
    "                'name': 'roberta-base',\n",
    "                'max_len': 128,\n",
    "                'batch_size': 8,\n",
    "                'epochs': 3,\n",
    "                'lr': 1e-5\n",
    "            },\n",
    "            'ALBERT': {\n",
    "                'name': 'albert-base-v2',\n",
    "                'max_len': 128,\n",
    "                'batch_size': 16,\n",
    "                'epochs': 3,\n",
    "                'lr': 3e-5\n",
    "            },\n",
    "            'electra-small': {\n",
    "                'name': 'google/electra-small-discriminator',\n",
    "                'max_len': 128,\n",
    "                'batch_size': 16,\n",
    "                'epochs': 3,\n",
    "                'lr': 2e-5\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def load_and_preprocess_data(self, df):\n",
    "        \"\"\"Load and preprocess the dataset\"\"\"\n",
    "        print(\"ðŸ“Š Dataset Overview:\")\n",
    "        print(f\"Total samples: {len(df)}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "        # Check label distribution\n",
    "        print(\"\\nðŸ“ˆ Label Distribution:\")\n",
    "        for col in self.label_columns:\n",
    "            positive_ratio = df[col].mean()\n",
    "            print(f\"{col}: {positive_ratio:.3f} ({positive_ratio*100:.1f}% positive)\")\n",
    "\n",
    "        # Sample down for faster training (adjust based on your needs)\n",
    "        # Using stratified sampling to maintain label distribution\n",
    "        sample_size = min(50000, len(df))  # Adjust this based on your resources\n",
    "        if len(df) > sample_size:\n",
    "            print(f\"\\nðŸŽ¯ Sampling {sample_size} examples for faster training...\")\n",
    "            df_sampled = df.sample(n=sample_size, random_state=42)\n",
    "        else:\n",
    "            df_sampled = df.copy()\n",
    "\n",
    "        # Split the data\n",
    "        X = df_sampled['comment_text'].values\n",
    "        y = df_sampled[self.label_columns].values\n",
    "\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y[:, 0]  # Stratify on toxic label\n",
    "        )\n",
    "\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp[:, 0]\n",
    "        )\n",
    "\n",
    "        print(f\"\\nðŸ“‹ Data Split:\")\n",
    "        print(f\"Training: {len(X_train)} samples\")\n",
    "        print(f\"Validation: {len(X_val)} samples\")\n",
    "        print(f\"Testing: {len(X_test)} samples\")\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    \n",
    "\n",
    "    def train_model(self, model_name, X_train, X_val, y_train, y_val):\n",
    "        print(f\"\\nðŸš€ Training {model_name}...\")\n",
    "        config = self.model_configs[model_name]\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config['name'])\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            config['name'],\n",
    "            num_labels=len(self.label_columns),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "\n",
    "        train_dataset = ToxicDataset(X_train, y_train, tokenizer, config['max_len'], model_name)\n",
    "        val_dataset = ToxicDataset(X_val, y_val, tokenizer, config['max_len'], model_name)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'./results_{model_name.lower()}',\n",
    "            num_train_epochs=config['epochs'],\n",
    "            per_device_train_batch_size=config['batch_size'],\n",
    "            per_device_eval_batch_size=config['batch_size'],\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=f'./logs_{model_name.lower()}',\n",
    "            logging_steps=100,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=500,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=500,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"auc\",\n",
    "            greater_is_better=True,\n",
    "            learning_rate=config['lr'],\n",
    "            adam_epsilon=1e-8,\n",
    "            max_grad_norm=1.0,\n",
    "            fp16=True if torch.cuda.is_available() else False,\n",
    "            dataloader_num_workers=0,\n",
    "            save_total_limit=1,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        model_dir = f\"/saved_model/{model_name}\"\n",
    "        model.save_pretrained(model_dir)\n",
    "        tokenizer.save_pretrained(model_dir)\n",
    "        print(f\"ðŸ“¦ Model and tokenizer saved to {model_dir}\")\n",
    "\n",
    "        self.models[model_name] = model\n",
    "        self.tokenizers[model_name] = tokenizer\n",
    "\n",
    "        # Save validation \n",
    "        # \n",
    "        # \n",
    "        # s\n",
    "        # thresholds = compute_optimal_thresholds(self, model_name, X_val, y_val)\n",
    "        # self.thresholds[model_name] = thresholds\n",
    "\n",
    "        # os.makedirs(\"saved_model\", exist_ok=True)\n",
    "\n",
    "        # # Optionally save thresholds to disk\n",
    "        # with open(f\"/saved_model/thresholds_{model_name}.json\", \"w\") as f:\n",
    "        #     json.dump(thresholds, f)\n",
    "\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(f\"âœ… {model_name} - Validation AUC: {eval_results['eval_auc']:.4f}, F1: {eval_results['eval_f1']:.4f}\")\n",
    "\n",
    "        return eval_results\n",
    "\n",
    "\n",
    "    def predict(self, text, model_name):\n",
    "        \"\"\"Make predictions using a specific model\"\"\"\n",
    "        if model_name not in self.models:\n",
    "            raise ValueError(f\"Model {model_name} not trained yet!\")\n",
    "\n",
    "        model = self.models[model_name]\n",
    "        tokenizer = self.tokenizers[model_name]\n",
    "\n",
    "        # Check if model is on CUDA, if so move to CPU for prediction\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "        # Tokenize input - handle DistilBERT token_type_ids issue\n",
    "        tokenizer_kwargs = {\n",
    "            'text': text,\n",
    "            'add_special_tokens': True,\n",
    "            'max_length': 128,\n",
    "            'padding': 'max_length',\n",
    "            'truncation': True,\n",
    "            'return_attention_mask': True,\n",
    "            'return_tensors': 'pt'\n",
    "        }\n",
    "\n",
    "        # Only add token_type_ids for models that support it (not DistilBERT)\n",
    "        if 'distilbert' not in model_name.lower():\n",
    "            tokenizer_kwargs['return_token_type_ids'] = True\n",
    "\n",
    "        inputs = tokenizer.encode_plus(**tokenizer_kwargs)\n",
    "\n",
    "        # Move inputs to the same device as model\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to(device)\n",
    "\n",
    "        # Make prediction\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
    "\n",
    "        # Create results dictionary\n",
    "        results = {}\n",
    "        for i, label in enumerate(self.label_columns):\n",
    "            results[label] = float(predictions[i])\n",
    "\n",
    "        return results\n",
    "\n",
    "    def evaluate_all_models(self, X_test, y_test):\n",
    "        \"\"\"Evaluate all trained models on test set\"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for model_name in self.models.keys():\n",
    "            print(f\"\\nðŸ” Evaluating {model_name} on test set...\")\n",
    "\n",
    "            model = self.models[model_name]\n",
    "            tokenizer = self.tokenizers[model_name]\n",
    "\n",
    "            # Create test dataset\n",
    "            test_dataset = ToxicDataset(X_test, y_test, tokenizer, 128, model_name)\n",
    "\n",
    "            # Create trainer for evaluation\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "            # Evaluate\n",
    "            eval_results = trainer.evaluate(test_dataset)\n",
    "            results[model_name] = {\n",
    "                'auc': eval_results['eval_auc'],\n",
    "                'f1': eval_results['eval_f1']\n",
    "            }\n",
    "\n",
    "            print(f\"ðŸ“Š {model_name} - Test AUC: {eval_results['eval_auc']:.4f}, F1: {eval_results['eval_f1']:.4f}\")\n",
    "\n",
    "        return results\n",
    "    \n",
    "    # --- END OF CLASS ---\n",
    "\n",
    "def compute_optimal_thresholds(detector, model_name, X_val, y_val):\n",
    "    print(f\"ðŸ”Ž Computing optimal thresholds for {model_name}...\")\n",
    "    model = detector.models[model_name]\n",
    "    tokenizer = detector.tokenizers[model_name]\n",
    "    max_len = detector.model_configs[model_name]['max_len']\n",
    "\n",
    "    model.eval()\n",
    "    val_dataset = ToxicDataset(X_val, y_val, tokenizer, max_len, model_name)\n",
    "    dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].numpy()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "        all_logits.append(logits)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_logits = np.vstack(all_logits)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    best_thresholds = []\n",
    "\n",
    "    for i in range(all_labels.shape[1]):\n",
    "        best_f1 = 0\n",
    "        best_thresh = 0.5\n",
    "        for thresh in np.arange(0.1, 0.9, 0.01):\n",
    "            preds = (all_logits[:, i] >= thresh).astype(int)\n",
    "            score = f1_score(all_labels[:, i], preds)\n",
    "            if score > best_f1:\n",
    "                best_f1 = score\n",
    "                best_thresh = thresh\n",
    "        best_thresholds.append(best_thresh)\n",
    "\n",
    "    print(f\"âœ… Optimal thresholds: {np.round(best_thresholds, 3).tolist()}\")\n",
    "    return best_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QGRr3PkWe8nd"
   },
   "outputs": [],
   "source": [
    "def train_toxic_detector(df):\n",
    "    \"\"\"Complete training pipeline\"\"\"\n",
    "    detector = ToxicCommentDetector()\n",
    "\n",
    "    # Load and preprocess data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = detector.load_and_preprocess_data(df)\n",
    "\n",
    "    # Train all models\n",
    "    validation_results = {}\n",
    "    for model_name in detector.model_configs.keys():\n",
    "        model_dir = f\"/saved_model/{model_name}\"\n",
    "\n",
    "        # Skip training if model is already saved\n",
    "        if os.path.exists(model_dir):\n",
    "            print(f\"âœ… Skipping {model_name}, model already exists at {model_dir}\")\n",
    "            \n",
    "            # Load model and tokenizer\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "            detector.models[model_name] = model\n",
    "            detector.tokenizers[model_name] = tokenizer\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            eval_results = detector.train_model(model_name, X_train, X_val, y_train, y_val)\n",
    "            validation_results[model_name] = eval_results\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error training {model_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_results = detector.evaluate_all_models(X_test, y_test)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ“‹ FINAL RESULTS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': list(test_results.keys()),\n",
    "        'Test_AUC': [results['auc'] for results in test_results.values()],\n",
    "        'Test_F1': [results['f1'] for results in test_results.values()]\n",
    "    })\n",
    "\n",
    "    results_df = results_df.sort_values('Test_AUC', ascending=False)\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    return detector, results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUTUBE ANALYSE FUNCTION**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lLLks7hJfKoE"
   },
   "outputs": [],
   "source": [
    "# Gradio Interface\n",
    "def create_gradio_interface(detector):\n",
    "    \"\"\"Create Gradio interface for the app\"\"\"\n",
    "\n",
    "    def predict_toxicity(text, model_name):\n",
    "        \"\"\"Predict toxicity for given text\"\"\"\n",
    "        if not text.strip():\n",
    "            return \"Please enter some text to analyze.\"\n",
    "\n",
    "        try:\n",
    "            results = detector.predict(text, model_name)\n",
    "\n",
    "            # Format results\n",
    "            output = f\"ðŸ” **Analysis Results using {model_name}:**\\n\\n\"\n",
    "            for label, score in results.items():\n",
    "                emoji = \"ðŸš¨\" if score > 0.5 else \"âœ…\"\n",
    "                output += f\"{emoji} **{label.replace('_', ' ').title()}**: {score:.3f} ({score*100:.1f}%)\\n\"\n",
    "\n",
    "            return output\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def compare_models(text):\n",
    "        \"\"\"Compare all models for the same text\"\"\"\n",
    "        if not text.strip():\n",
    "            return \"Please enter some text to analyze.\", None\n",
    "\n",
    "        try:\n",
    "            all_results = {}\n",
    "            for model_name in detector.models.keys():\n",
    "                results = detector.predict(text, model_name)\n",
    "                all_results[model_name] = results\n",
    "\n",
    "            # Create comparison chart\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "            models = list(all_results.keys())\n",
    "            labels = detector.label_columns\n",
    "            x = np.arange(len(labels))\n",
    "            width = 0.25\n",
    "\n",
    "            for i, model in enumerate(models):\n",
    "                scores = [all_results[model][label] for label in labels]\n",
    "                ax.bar(x + i*width, scores, width, label=model, alpha=0.8)\n",
    "\n",
    "            ax.set_xlabel('Toxicity Categories')\n",
    "            ax.set_ylabel('Probability Score')\n",
    "            ax.set_title(f'Model Comparison for: \"{text[:50]}...\"')\n",
    "            ax.set_xticks(x + width)\n",
    "            ax.set_xticklabels([label.replace('_', ' ').title() for label in labels], rotation=45)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Format text results\n",
    "            comparison_text = \"ðŸ“Š **Model Comparison Results:**\\n\\n\"\n",
    "            for model_name, results in all_results.items():\n",
    "                comparison_text += f\"**{model_name}:**\\n\"\n",
    "                for label, score in results.items():\n",
    "                    emoji = \"ðŸš¨\" if score > 0.5 else \"âœ…\"\n",
    "                    comparison_text += f\"  {emoji} {label.replace('_', ' ').title()}: {score:.3f}\\n\"\n",
    "                comparison_text += \"\\n\"\n",
    "\n",
    "            return comparison_text, fig\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\", None\n",
    "        \n",
    "    YOUTUBE_API_KEY=\"AIzaSyCnJQ1Ws1EjeBrZlfSuQWyEVzk5rVhiWl4\"\n",
    "\n",
    "    def extract_video_id(url):\n",
    "        pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
    "        match = re.search(pattern, url)\n",
    "        return match.group(1) if match else None\n",
    "\n",
    "    def fetch_comments(video_id, max_comments=20):\n",
    "        youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=max_comments,\n",
    "            order=\"relevance\",\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments = []\n",
    "        for item in response[\"items\"]:\n",
    "            text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(text)\n",
    "        return comments\n",
    "\n",
    "    def analyze_youtube_comments(url, model_name):\n",
    "        video_id = extract_video_id(url)\n",
    "        if not video_id:\n",
    "            return \"âŒ Invalid YouTube URL. Please try again.\"\n",
    "\n",
    "        try:\n",
    "            comments = fetch_comments(video_id)\n",
    "        except Exception as e:\n",
    "            return f\"âŒ Error fetching comments: {str(e)}\"\n",
    "\n",
    "        formatted_output = f\"ðŸŽ¥ **Toxicity Analysis of Top YouTube Comments using {model_name}**\\n\\n\"\n",
    "\n",
    "        for i, comment in enumerate(comments, 1):\n",
    "            predictions = detector.predict(comment, model_name)\n",
    "            formatted_output += f\"---\\n**#{i}. ðŸ’¬ Comment:**\\n> {comment.strip()}\\n\\n**ðŸ” Analysis:**\\n\"\n",
    "            for label, score in predictions.items():\n",
    "                emoji = \"ðŸš¨\" if score > 0.5 else \"âœ…\"\n",
    "                formatted_output += f\"{emoji} **{label.replace('_', ' ').title()}**: {score:.3f} ({score*100:.1f}%)\\n\"\n",
    "            formatted_output += \"\\n\"\n",
    "\n",
    "        return formatted_output\n",
    "\n",
    "# twiter function\n",
    "    def scrape_twitter_replies(tweet_url, username, password, max_scrolls=5):\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless=new\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "        driver.get(\"https://twitter.com/login\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        driver.find_element(By.NAME, \"text\").send_keys(username)\n",
    "        driver.find_element(By.XPATH, '//span[text()=\"Next\"]').click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        driver.find_element(By.NAME, \"password\").send_keys(password)\n",
    "        driver.find_element(By.XPATH, '//span[text()=\"Log in\"]').click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        driver.get(tweet_url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        replies = set()\n",
    "        for _ in range(max_scrolls):\n",
    "            elements = driver.find_elements(By.XPATH, '//div[@data-testid=\"tweetText\"]')\n",
    "            for el in elements:\n",
    "                text = el.text.strip()\n",
    "                if text:\n",
    "                    replies.add(text)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(3)\n",
    "\n",
    "        driver.quit()\n",
    "        return list(replies)\n",
    "    \n",
    "    from twitter_scraper import scrape_replies\n",
    "    def analyze_twitter_replies(tweet_url, model_name):\n",
    "        twitter_username = \"NLPscrape\"     # use environment variables or config for real use\n",
    "        twitter_password = \"nlpScrape\"\n",
    "\n",
    "        try:\n",
    "            replies = scrape_replies(tweet_url, twitter_username, twitter_password)\n",
    "        except Exception as e:\n",
    "            return f\"âŒ Error fetching Twitter replies: {str(e)}\"\n",
    "\n",
    "        if not replies:\n",
    "            return \"âš ï¸ No replies found.\"\n",
    "\n",
    "        formatted_output = f\"ðŸ¦ **Toxicity Analysis of Twitter Replies using {model_name}**\\n\\n\"\n",
    "\n",
    "        for i, reply in enumerate(replies, 1):\n",
    "            predictions = detector.predict(reply, model_name)\n",
    "            formatted_output += f\"---\\n**#{i}. ðŸ’¬ Reply:**\\n> {reply.strip()}\\n\\n**ðŸ” Analysis:**\\n\"\n",
    "            for label, score in predictions.items():\n",
    "                emoji = \"ðŸš¨\" if score > 0.5 else \"âœ…\"\n",
    "                formatted_output += f\"{emoji} **{label.replace('_', ' ').title()}**: {score:.3f} ({score*100:.1f}%)\\n\"\n",
    "            formatted_output += \"\\n\"\n",
    "\n",
    "        return formatted_output\n",
    "\n",
    "\n",
    "\n",
    "    # Create Gradio interface\n",
    "    with gr.Blocks(title=\"ðŸ›¡ï¸ Toxic Comment Detector\", theme=gr.themes.Soft()) as interface:\n",
    "        gr.Markdown(\"\"\"\n",
    "        # ðŸ›¡ï¸ Toxic Comment Detector\n",
    "\n",
    "        This app uses four different pre-trained models to detect toxicity in comments.\n",
    "        Enter your text below and choose a model to get predictions, or compare all models at once!\n",
    "        \"\"\")\n",
    "\n",
    "        with gr.Tab(\"Single Model Prediction\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    text_input = gr.Textbox(\n",
    "                        label=\"Enter comment to analyze\",\n",
    "                        placeholder=\"Type your comment here...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    model_dropdown = gr.Dropdown(\n",
    "                        choices=list(detector.models.keys()),\n",
    "                        label=\"Select Model\",\n",
    "                        value=list(detector.models.keys())[0] if detector.models else None\n",
    "                    )\n",
    "                    predict_btn = gr.Button(\"ðŸ” Analyze Toxicity\", variant=\"primary\")\n",
    "\n",
    "                with gr.Column():\n",
    "                    single_output = gr.Markdown(label=\"Results\")\n",
    "\n",
    "            predict_btn.click(\n",
    "                predict_toxicity,\n",
    "                inputs=[text_input, model_dropdown],\n",
    "                outputs=single_output\n",
    "            )\n",
    "\n",
    "        with gr.Tab(\"Compare All Models\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    compare_text_input = gr.Textbox(\n",
    "                        label=\"Enter comment to analyze\",\n",
    "                        placeholder=\"Type your comment here...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    compare_btn = gr.Button(\"ðŸ“Š Compare All Models\", variant=\"primary\")\n",
    "\n",
    "                with gr.Column():\n",
    "                    compare_output = gr.Markdown(label=\"Comparison Results\")\n",
    "\n",
    "            compare_plot = gr.Plot(label=\"Visual Comparison\")\n",
    "\n",
    "            compare_btn.click(\n",
    "                compare_models,\n",
    "                inputs=compare_text_input,\n",
    "                outputs=[compare_output, compare_plot]\n",
    "            )\n",
    "\n",
    "        with gr.Tab(\"Analyze YouTube Comments\"):\n",
    "            with gr.Column():\n",
    "                yt_url_input = gr.Textbox(\n",
    "                    label=\"Enter YouTube Video URL\",\n",
    "                    placeholder=\"e.g. https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n",
    "                )\n",
    "                yt_model_dropdown = gr.Dropdown(\n",
    "                    choices=list(detector.models.keys()),\n",
    "                    label=\"Select Model\",\n",
    "                    value=list(detector.models.keys())[0]\n",
    "                )\n",
    "                yt_btn = gr.Button(\"ðŸŽ¥ Analyze Comments\", variant=\"primary\")\n",
    "                yt_markdown_output = gr.Markdown(label=\"Toxicity Prediction per Comment\")\n",
    "\n",
    "            yt_btn.click(\n",
    "                analyze_youtube_comments,\n",
    "                inputs=[yt_url_input, yt_model_dropdown],\n",
    "                outputs=yt_markdown_output\n",
    "            )\n",
    "\n",
    "        with gr.Tab(\"Analyze Twitter Replies\"):\n",
    "            with gr.Column():\n",
    "                twitter_url_input = gr.Textbox(\n",
    "                    label=\"Enter Tweet URL\",\n",
    "                    placeholder=\"e.g. https://twitter.com/elonmusk/status/123456789\"\n",
    "                )\n",
    "                twitter_model_dropdown = gr.Dropdown(\n",
    "                    choices=list(detector.models.keys()),\n",
    "                    label=\"Select Model\",\n",
    "                    value=list(detector.models.keys())[0]\n",
    "                )\n",
    "                twitter_btn = gr.Button(\"ðŸ¦ Analyze Twitter Replies\", variant=\"primary\")\n",
    "                twitter_output = gr.Markdown(label=\"Toxicity Prediction per Reply\")\n",
    "\n",
    "            twitter_btn.click(\n",
    "                analyze_twitter_replies,\n",
    "                inputs=[twitter_url_input, twitter_model_dropdown],\n",
    "                outputs=twitter_output\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        gr.Markdown(\"\"\"\n",
    "        ---\n",
    "        ### ðŸ“ Model Information:\n",
    "        - **DistilBERT**: Lightweight and fast, good for real-time applications\n",
    "        - **RoBERTa**: Robust and accurate, optimized training approach\n",
    "        - **ALBERT**: Parameter-efficient, good balance of speed and accuracy\n",
    "        - **ELECTRA-Small**: Very lightweight and fast, pre-trained with a novel discriminator approach\n",
    "\n",
    "        ### ðŸ·ï¸ Labels Explained:\n",
    "        - **Toxic**: General toxicity\n",
    "        - **Severe Toxic**: Extremely toxic content\n",
    "        - **Obscene**: Obscene language\n",
    "        - **Threat**: Threatening language\n",
    "        - **Insult**: Insulting content\n",
    "        - **Identity Hate**: Hate speech targeting identity groups\n",
    "        \"\"\")\n",
    "\n",
    "    return interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LGS6ndvPfae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Dataset Overview:\n",
      "Total samples: 159571\n",
      "Columns: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "\n",
      "ðŸ“ˆ Label Distribution:\n",
      "toxic: 0.096 (9.6% positive)\n",
      "severe_toxic: 0.010 (1.0% positive)\n",
      "obscene: 0.053 (5.3% positive)\n",
      "threat: 0.003 (0.3% positive)\n",
      "insult: 0.049 (4.9% positive)\n",
      "identity_hate: 0.009 (0.9% positive)\n",
      "\n",
      "ðŸŽ¯ Sampling 50000 examples for faster training...\n",
      "\n",
      "ðŸ“‹ Data Split:\n",
      "Training: 35000 samples\n",
      "Validation: 7500 samples\n",
      "Testing: 7500 samples\n",
      "âœ… Skipping DistilBERT, model already exists at /saved_model/DistilBERT\n",
      "âœ… Skipping RoBERTa, model already exists at /saved_model/RoBERTa\n",
      "âœ… Skipping ALBERT, model already exists at /saved_model/ALBERT\n",
      "âœ… Skipping electra-small, model already exists at /saved_model/electra-small\n",
      "\n",
      "ðŸ” Evaluating DistilBERT on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b63e7c45b047768f2c0c4f4444e870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š DistilBERT - Test AUC: 0.9891, F1: 0.5289\n",
      "\n",
      "ðŸ” Evaluating RoBERTa on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d4042a0b384f818cffc379fcc67f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š RoBERTa - Test AUC: 0.9851, F1: 0.4546\n",
      "\n",
      "ðŸ” Evaluating ALBERT on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3067726b2fc34171b5b3dcad0c4a6c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š ALBERT - Test AUC: 0.9825, F1: 0.4389\n",
      "\n",
      "ðŸ” Evaluating electra-small on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d843c8fddeb5475b827fb505457b3237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š electra-small - Test AUC: 0.9805, F1: 0.4336\n",
      "\n",
      "==================================================\n",
      "ðŸ“‹ FINAL RESULTS SUMMARY\n",
      "==================================================\n",
      "        Model  Test_AUC  Test_F1\n",
      "   DistilBERT  0.989091 0.528857\n",
      "      RoBERTa  0.985051 0.454623\n",
      "       ALBERT  0.982461 0.438937\n",
      "electra-small  0.980548 0.433556\n"
     ]
    }
   ],
   "source": [
    "#train models\n",
    "detector, results=train_toxic_detector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "mtFv0M5Mo6im"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lauch gradio interface\n",
    "interface=create_gradio_interface(detector)\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pFFsIyI3SLs7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded DistilBERT\n",
      "âœ… Loaded RoBERTa\n",
      "âœ… Loaded ALBERT\n",
      "âœ… Loaded electra-small\n",
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is to run instantly, no need to retrain the models again\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Rebuild detector instance\n",
    "detector = ToxicCommentDetector()\n",
    "\n",
    "# List of saved models\n",
    "model_names = [\"DistilBERT\", \"RoBERTa\", \"ALBERT\", \"electra-small\"]\n",
    "\n",
    "# Load models from Drive\n",
    "for model_name in model_names:\n",
    "    try:\n",
    "        model_path = f\"/saved_model/{model_name}\"\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=len(detector.label_columns))\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        detector.models[model_name] = model\n",
    "        detector.tokenizers[model_name] = tokenizer\n",
    "        print(f\"âœ… Loaded {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load {model_name}: {e}\")\n",
    "\n",
    "# Launch Gradio UI\n",
    "gr_interface = create_gradio_interface(detector)\n",
    "gr_interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aefnz8YVSQbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Trying to load from: /saved_model/electra-small\n"
     ]
    }
   ],
   "source": [
    "print(f\"ðŸ” Trying to load from: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': 0.9812203645706177,\n",
       " 'severe_toxic': 0.10110896825790405,\n",
       " 'obscene': 0.8203717470169067,\n",
       " 'threat': 0.03380442410707474,\n",
       " 'insult': 0.9233447909355164,\n",
       " 'identity_hate': 0.10019809752702713}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.predict(\"You're a horrible idiot and should be banned.\", \"RoBERTa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
